# 6章　ゴルーチンとGoランタイム

並行処理のコードを書いている最中に、裏側でランタイムがどのように調和させているか知る必要があることは非常にまれ。

ランタイムの動作に関する知識は役に立つし、欄他夢のおかげで並行性のモデル化での議論はなりたつ。

裏側はすごい叡智の量で、性能がより高いものにする素晴らしい仕事をし、詳細の抽象化をし開発者がさわる部分にはとても単純な表面だけを見せている

## 6.1 ワークスティーリング

GoがゴルーチンをOSスレッド上へのマルチプレキシングをするが、そこで使っているアルゴリズムはワークスティーリング(仕事を奪う)線らy九

#### フェアスケジューリング

各プロセッサが平等に同数のタスク数を持つような戦略

`n` 個のプロセッサーPと実行すべき `x` 個のタスクT

各プロセッサは`x/n`個のタスクを受け取る

fork-joinモデルを使って並行処理を計画している。

タスク同士は互いに依存しあっていて、ナイーブに分散させると
→　使用率が高くないプロセッサーが出てしまう

あるプロセッサで稼働しているタスクと同じデータを必要としていたりするので、キャッシュの局所性が乏しくなる

タスクの所持時間の長さの違いがあると→アイドル状態になるプロセッサが生じる

タスクが互いに依存している場合→アイドル状態が発生する。

#### 問題の解決案1(キューでロードバランス)

FIFOキューが役に立つ基本的なロードバランス問題みたい

→　プロセッサが余裕あるとき or ジョイン待ちでブロックしているときにキューから取り出す(1つのワークスティーリング)

キューという集中的なデータ構造を導入している

→　コストがかかる
→　キャッシュの局所性の問題も悪化

粒度の大きなものなら正しい取り組みだが、ゴルーチンの粒度は大きなものではない。

#### 問題の解決案2

個々のプロセッサー専用のスレッドと両端キュー(デック`deque`)を持たせる

スレッドごとにデックを導入することで、中央集権のデータ構造の問題を解決

- キャッシュの局所性
- プロセッサーの使用率

→ ワークスティーリングアルゴリズムが分散デックに対して操作を行う規則を見よう

実行スレッドがあった場合の基本的な規則4つ

フィボナッチ数列を再帰的に計算しているプログラム

規則に従ったコールスタック、ワークデックの表

デックの最後尾にあるタスクの性質
- 最後尾のタスクはほぼ間違いなく親の合流を完了させるために必要になる
- 最後尾のタスクはほぼ間違いなく依然としてプロセッサーのキャッシュにある

結論：このようにタスクをスケジュールすると多くの暗黙的な利益が得られる。

### 6.1.1. タスクと継続どちらを盗むのか

## 6.2 全ての開発者にこの言葉を贈ります

Q. 開発者がゴルーチンを扱うときに何が必要か

A. `go` というキーワード。以上！

`go` というキーワードにより、自動的にタスクが動いているマシン上で最も効率的な方法でそのタスクをスケジュールしたことになる。
新しい手法や、複雑なデータ構造、スケジューリングアルゴリズムを理解する必要はない。

スケール、効率、単純、これこそがゴルーチンをこれほどまでに魅力的にしている。

## 6.3 結論

Goにおける並行処理の全貌を辿り終えた。

1. 最初の原則
2. 基本的な使い方、パターン
3. ランタイムの動作

素晴らしいハックのすべての助けにならんことを。

