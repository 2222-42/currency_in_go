# 6章　ゴルーチンとGoランタイム

並行処理のコードを書いている最中に、裏側でランタイムがどのように調和させているか知る必要があることは非常にまれ。

ランタイムの動作に関する知識は役に立つし、欄他夢のおかげで並行性のモデル化での議論はなりたつ。

裏側はすごい叡智の量で、性能がより高いものにする素晴らしい仕事をし、詳細の抽象化をし開発者がさわる部分にはとても単純な表面だけを見せている

## 6.1 ワークスティーリング

GoがゴルーチンをOSスレッド上へのマルチプレキシングをするが、そこで使っているアルゴリズムはワークスティーリング(仕事を奪う)線らy九

#### フェアスケジューリング

各プロセッサが平等に同数のタスク数を持つような戦略

`n` 個のプロセッサーPと実行すべき `x` 個のタスクT

各プロセッサは`x/n`個のタスクを受け取る

fork-joinモデルを使って並行処理を計画している。

タスク同士は互いに依存しあっていて、ナイーブに分散させると
→　使用率が高くないプロセッサーが出てしまう

あるプロセッサで稼働しているタスクと同じデータを必要としていたりするので、キャッシュの局所性が乏しくなる

タスクの所持時間の長さの違いがあると→アイドル状態になるプロセッサが生じる

| time | P1 | P2 |
|---|---|---|
|  | T1 | T2 |
| n+a | T3 | T2 |
| n+a+b | (idle) | T4 |

タスクが互いに依存している場合→アイドル状態が発生する。

| time | P1 | P2 |
|---|---|---|
|  | T1 | T2 |
| n+a | (blocked) | T2 |
| n+a+b | (blocked) | T4 |
| n+a+b+c | T1 | (idle) |
| n+a+b+c+d | T3 | (idle) |


#### 問題の解決案1(キューでロードバランス)

FIFOキューが役に立つ基本的なロードバランス問題みたい

→　プロセッサが余裕あるとき or ジョイン待ちでブロックしているときにキューから取り出す(1つのワークスティーリング)

キューという集中的なデータ構造を導入している

→　コストがかかる
→　キャッシュの局所性の問題も悪化

粒度の大きなものなら正しい取り組みだが、ゴルーチンの粒度は大きなものではない。

#### 問題の解決案2

個々のプロセッサー専用のスレッドと両端キュー(デック`deque`)を持たせる

スレッドごとにデックを導入することで、中央集権のデータ構造の問題を解決

筆者の提示した疑問：

1. キャッシュの局所性
2. プロセッサーの使用率
3. タスクの処理がP1で始まって、そこから派生するタスクがすべてP1のキューにおかれたら、どうしたら処理をP2に任せられるか
4. タスクをデック間で移動する際にコンテキストスイッチの問題は発生しないのでしょうか
(コンテキストスイッチ (context switch) とは、複数のプロセスが1つのCPUを共有できるように、CPUの状態(コンテキスト (情報工学))を保存したり復元したりする過程のことである)

分岐(fork)とは、ゴルーチンが開始するとき、合流(join)地点とは2つ以上のゴルーチンがチャネルやsyncパッケージ内の型をとおして同期されるとき。

ワークスティーリングアルゴリズムが分散デックに対して操作を行う規則：

0. ある実行スレッドがあった時に、
1. 分岐地点では、タスクをそのスレッドに紐づいているデックの最後尾に追加
2. そのスレッドがアイドルな時は、他の任意のスレッドに紐づいたデックの先頭から処理を盗む
3. まだ実現していない合流地点(まだ同期しているゴルーチンが完了していない)において、そのスレッドが持っているデックの最後尾からタスクを取り出す
4. もしスレッドのデックが空ならば、次のいずれかを行う
   - 合流地点で停止する
   - 任意のスレッドに紐づいたデックの先頭からタスクを盗む。

フィボナッチ数列を再帰的に計算しているプログラム

規則に従ったコールスタック、ワークデックの表

call main:

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine) |  |  |  |

call `fib(4)`:

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine) | fib(4) |  |  |

この時、T1かT2がfib(4) への呼び出しをつかさどるゴルーチンを盗む

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  |  |  |
| fib(4) |  |  |  |

規則1より、fib(3)とfib(2)をT1のデックの最後尾に追加

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) | fib(3) |  |  |
| fib(4) | fib(2) |  |  |

規則2より、アイドルなT2は、T1のデックの先頭からfib(3)を盗む

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) | fib(2) | fib(3) |  |
| fib(4) |  |  |  |

fib(4)は処理を続けられないので、まだ実現していない合流地点なので、規則3より、T1の最後尾のタスクを取り出す

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  | fib(3) |  |
| fib(4)(未達の合流地点) |  |  |  |
| fib(2) |  |  |  |

fib(3)の呼び出しから新しくスケジュールされたゴルーチンがワークデックに追加される

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  | fib(3) | fib(2) |
| fib(4)(未達の合流地点) |  |  | fib(1) |
| fib(2) |  |  |  |

T1のfib(2)で脱出

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  | fib(3) | fib(2) |
| fib(4)(未達の合流地点) |  |  | fib(1) |
| (1を返す) |  |  |  |

規則2より、アイドルなT2はT2のデックの最後尾からタスクを取り出す

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  | fib(3)(未達の合流地点) | fib(2) |
| fib(4)(未達の合流地点) |  | fib(1) |  |
| (1を返す) |  |  |  |

規則2より、アイドルなT1はT2のデックの最後尾からタスクを取り出す

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  | fib(3)(未達の合流地点) |  |
| fib(4)(未達の合流地点) |  | fib(1) |  |
| fib(2) |  |  |  |

T2のfib(1)で脱出

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  | fib(3)(未達の合流地点) |  |
| fib(4)(未達の合流地点) |  | (1を返す) |  |
| fib(2) |  |  |  |

T1のfib(2)で脱出

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  | fib(3)(未達の合流地点) |  |
| fib(4)(未達の合流地点 (<-　_ + 1)) |  | (1を返す) |  |
| (1を返す) |  |  |  |

合流する

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  | (2を返す) |  |
| fib(4)(未達の合流地点 (<-　_ + 1)) |  |  |  |

合流する

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (main goroutine)(未達の合流地点) |  |  |  |
| (3を返す) |  |  |  |

合流する

| T1 call stack | T1 work deque | T2 call stack | T2 work deque |
|---|---|---|---|
| (3を返す) |  |  |  |

デックの最後尾にあるタスクの性質
- 最後尾のタスクはほぼ間違いなく親の合流を完了させるために必要になる
  - つまり、合流を素早く完了させるのであるから、プログラムが早く実行されることになる
- 最後尾のタスクはほぼ間違いなく依然としてプロセッサーのキャッシュにある
  - 最後尾のタスクは、今処理しているタスクの前に最後に処理したものだから、CPUのキャッシュにこのタスクに関する情報が残っている可能性があるから、規則3はキャッシュミスを少なくすることになる

結論：このようにタスクをスケジュールすると多くの暗黙的な利益が得られる。

### 6.1.1. タスクと継続どちらを盗むのか

どんなタスクをデックに入れたりそこから盗んだりするか

fork-joinのパラダイムの2つの選択肢
1. タスク: 6.1でやった内容
2. 継続: 本節でやること

ゴルーチンは仕事の中身をうまくカプセル化した関数を管理している

Goのワークスティーリングアルゴリズムがデックに入れたり盗んでいるのは継続

合流地点について検討しよう

完了条件を満たしていない合流地点に到達(停止した合流)
実行している処理を停止して、タスクを盗む

タスクスティーリング(別名「チャイルドスティーリング」)も継続スティーリングも停止した合流があるが、停止が発生する頻度に重要な違いがある。

原則から考えて、ゴルーチンをスケジュールするときは即時にそれを処理するのが理にかなっている

継続をデックの最後尾に入れる　→　その継続を盗まれる確率は減る　→　呼び戻しやすい　→　停止をさけられる（分岐したタスクは関数呼び出しにとても良く似たものになる）

スレッドはゴルーチンの実行にジャンプして、その処理が完了してから継続に戻る

継続スティーリングについて、次の規約を追加

- 継続がデックに追加されたときは、それを「Xの継続」として列挙
- 継続が実行のためにデックから取り出されたら、暗黙的に継続をfibの次の呼び出しに変換する

規則に従ったコールスタック、ワークデックの表：

コールチェインがなめらかな感じがするね。直列

流れを確認したら、直列に物事を処理できるようにするのに継続が役立っている

(「ストールした合流地点」ってなんだ？ stealの過去形のstoleか？ 未達の合流地点のことか？)

シングルスレッドでのゴルーチンを使ったランタイムが普通に関数を使った場合と同じように動く

継続を盗む利点のまとめの表
（「チャイルド」ってなんだよ、タスクのことか？）

なんですべてのワークスティーリングアルゴリズムは継続スティーリングを実装していないのか
→　継続スティーリングは通常コンパイラのサポートが必要になる。
→　Goは継続スティーリングを採用している

#### Goのスケジューラーの概念とその動作原理

Goのスケジューラーの三つの概念:
1. G: ゴルーチン　(現在のゴルーチンの状態)
2. M: OSスレッド　→　スレッド
3. P: コンテキスト　→　デック

Goランタイムでは、Mが起動されて、それがPを管理して、そのPがGをスケジュールして管理する。

(謎の図)

- 論理CPU：コンテキスト　= 1:1
- CPUコア数:OSスレッド数　# 1:1

Goランタイムでたった1つ保証できること：全コンテキストを扱うためのOSスレッドが最低1つあるということ

ゴルーチンがブロックされているときに何が起きるか
→　性能の問題が起きる
→　GoはコンテキストをOSスレッドから引き離して、コンテキストが他のブロックされていないOSスレッドに引き渡せるようにする
→　ブロックされたゴルーチンはブロックされたスレッドに紐づいたまま
→　ブロックが解放　→　コンテキストを奪い返す

コンテキストを奪い返して処理を続けようとする(他のメリットとして、スレッドプールを作っておくことで、スレッド起動の重いコストをは割らずに、即座に他のゴルーチンを起動できるようになる、というものがある)が、うまくいかない場合：
OSスレッドはゴルーチンをグローバルコンテキスト上に置いた後スリープし、Goランタイムのスレッドプールにいれられ、あとで使われるまで待機する

グローバルコンテキストは、本書で述べていたワークスティーリングアルゴリズムの議論には適合しない。
→　グローバルコンテキストに置かれたゴルーチンが恒久的に存在し続けないようにするためのいくつかの追加の手順が追加されている。他のOSスレッドのコンテキストを確認する前に、グローバルコンテキストを確認する。

Goはゴルーチンが任意の関数呼び出しによってランタイムに割り込まれることを許している。

入出力もシステムコールも関数呼び出しもしていないゴルーチンは例外で問題として残っている

## 6.2 全ての開発者にこの言葉を贈ります

Q. 開発者がゴルーチンを扱うときに何が必要か

A. `go` というキーワード。以上！

`go` というキーワードにより、自動的にタスクが動いているマシン上で最も効率的な方法でそのタスクをスケジュールしたことになる。
新しい手法や、複雑なデータ構造、スケジューリングアルゴリズムを理解する必要はない。

スケール、効率、単純、これこそがゴルーチンをこれほどまでに魅力的にしている。

## 6.3 結論

Goにおける並行処理の全貌を辿り終えた。

1. 最初の原則
2. 基本的な使い方、パターン
3. ランタイムの動作

素晴らしいハックのすべての助けにならんことを。

